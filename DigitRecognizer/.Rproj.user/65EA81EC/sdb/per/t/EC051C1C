{
    "contents" : "library(ggplot2)\nlibrary(e1071)\nlibrary(ElemStatLearn)\nlibrary(plyr)\nlibrary(class)\n\nimport.csv <- function(filename){\n  return(read.csv(filename, sep = \",\", header = TRUE, stringsAsFactors = FALSE))\n}\n\ntrain.data <- import.csv(\"train.csv\")\ntest.data <- import.csv(\"test.csv\")\n# test.data <- train.data[30001:32000,]\n# train.data <- train.data[1:6000,]\n\n#Performing PCA on the dataset to reduce the dimensionality of the data\n\nget_PCA <- function(dataset){\n  dataset.cov <- cov(dataset, use = \"everything\")\n  dataset.cov.svd <- svd(dataset.cov)\n  return(dataset.cov.svd)\n}\n\n#Pre-process train\n\npreprocess <- function(train, test){\n  features.unit.variance <- names(train[, sapply(train, function(v) var(v, na.rm=TRUE)==0)])\n  train <- train[,!(colnames(train) %in% features.unit.variance)]\n  train.label <- data.frame(label = train$label)\n  train <- train[,!(colnames(train) %in% \"label\")]\n  norm.data <- train\n  mean_sdev_train <- normalize(norm.data)\n  train <- data.matrix(train)\n  train <- scale(train, scale = T, center = T)\n  pr.comp <- get_PCA(train)\n  train <- data.frame(train %*% pr.comp$u[,1:200])\n  #train <- train[,1:80]\n  train <- cbind(train, train.label)\n  #Project test data in the training data space\n  test <- test[,!(colnames(test) %in% features.unit.variance)]\n  train.mean <- mean_sdev_train$mean.data\n  train.sdev <- mean_sdev_train$sdev\n  #Normalize the test data according to the train data\n  test = data.matrix(test)\n  for(i in (1:nrow(test))){\n    test[i,] = test[i,] - train.mean\n    test[i,] = test[i,] / train.sdev\n  }\n  test <- data.frame(test %*% pr.comp$u[,1:200])\n  #test <- test[,1:80]\n  result <- list(train = train, test = test)\n  return(result)\n}\n\n#Normalize train data\nnormalize <- function(data){\n  mean.data = vector()\n  sdev = vector()\n  for(i in (1:ncol(data))){\n    mean.data[i] = mean(data[,i])\n    sdev[i] = sd(data[,i])\n  }\n  result <- list(mean.data = mean.data, sdev = sdev)\n}\n\n#Perform k-fold cross validation\n\ndo_cv_class <- function(df, k, classifier){\n  num_of_nn = gsub(\"[^[:digit:]]\",\"\",classifier)\n  classifier = gsub(\"[[:digit:]]\",\"\",classifier)\n  if(num_of_nn == \"\")\n  {\n    classifier = c(\"get_pred_\",classifier)\n  }\n  else\n  {\n    classifier = c(\"get_pred_k\",classifier)\n    num_of_nn = as.numeric(num_of_nn)\n  }\n  classifier = paste(classifier,collapse = \"\")\n  func_name <- classifier\n  output = vector()\n  size_distr = c()\n  n = nrow(df)\n  for(i in 1:n)\n  {\n    a = 1 + (((i-1) * n)%/%k)\n    b = ((i*n)%/%k)\n    size_distr = append(size_distr, b - a + 1)\n  }\n  \n  row_num = 1:n\n  sampling = list()\n  for(i in 1:k)\n  {\n    s = sample(row_num,size_distr)\n    sampling[[i]] = s\n    row_num = setdiff(row_num,s)\n  }\n  prediction.df = data.frame()\n  outcome.list = list()\n  \n  for(i in 1:k)\n  {\n    testSample = sampling[[i]]\n    train_set = df[-testSample,]\n    test_set = df[testSample,]\n    test_set_label = test_set$label\n    test_set = test_set[,!colnames(test_set) %in% \"label\"]\n    datasets = preprocess(train_set, test_set)\n    train_set = datasets$train\n    test_set = datasets$test\n    if(num_of_nn == \"\")\n    {\n      classifier = match.fun(classifier)\n      result = classifier(train_set,test_set)\n      confusion.matrix <- table(pred = result, true = test_set_label)\n      accuracy <- sum(diag(confusion.matrix)*100)/sum(confusion.matrix)\n      print(confusion.matrix)\n      outcome <- list(sample_ID = i, Accuracy = accuracy)\n      outcome.list <- rbind(outcome.list, outcome)\n    }\n    else\n    {\n      \n      classifier = match.fun(classifier)\n      result = classifier(train_set,test_set)\n      confusion.matrix <- table(pred = result, true = test_set_label)\n      accuracy <- sum(diag(confusion.matrix)*100)/sum(confusion.matrix)\n      print(confusion.matrix)\n      outcome <- list(sample_ID = i, Accuracy = accuracy)\n      outcome.list <- rbind(outcome.list, outcome)\n    }\n  }\n  return(outcome.list)\n}\n\n#Support Vector Machines with linear kernel\nget_pred_svm <- function(train,test){\n  digit.class.train <- as.factor(train$label)\n  train.features <- train[,!colnames(train) %in% \"label\"]\n  svm.model <- svm(train.features, digit.class.train, cost = 1000, gamma = 1/ncol(train.features), kernel = \"radial\")\n  result <- (0:9)[predict(svm.model, test)]\n  return(result)\n}\n\n#KNN model\nget_pred_knn <- function(train,test){\n  digit.class.train <- as.factor(train$label)\n  train.features <- train[,!colnames(train) %in% \"label\"]\n  knn.model <- knn(train.features, test, digit.class.train)\n  return(knn.model)\n}\n\n#Final run\n\nget_output <- function(train_set, test_set){\n  datasets = preprocess(train_set, test_set)\n  train_set = datasets$train\n  test_set = datasets$test\n  \n  result = get_pred_svm(train_set,test_set)\n  return(result)\n}\n\n",
    "created" : 1403485299078.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3467450940",
    "id" : "EC051C1C",
    "lastKnownWriteTime" : 1403486232,
    "path" : "~/Assignments/Machine Learning/Digit Recognition/DigitRecognizer/Digitrecognizer.R",
    "project_path" : "Digitrecognizer.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}